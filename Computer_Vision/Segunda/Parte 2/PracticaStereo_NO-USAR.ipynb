{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Práctica de reconstrucción.  Parte II. Visión estéreo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visión Computacional 2018-19 <br>\n",
    "Practica 2. 29 de octubre de 2018"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Este enunciado está en el archivo \"PracticaStereo.ipynb\" o su versión \"pdf\" que puedes encontrar en el Aula Virtual."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Objetivos\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Los objetivos de esta práctica son:\n",
    "* reconstruir puntos de una escena a partir de una serie de correspondencias manuales entre dos imágenes calibradas;\n",
    "* determinar la geometría epipolar de un par de cámaras a partir de sus matrices de proyección;\n",
    "* implementar la búsqueda automática de correspondencias que use las restricciones impuestas por la geometría epipolar, aplicando para ello métodos de cortes de grafos;\n",
    "* realizar una reconstrucción densa de la escena."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Requerimientos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para esta práctica es necesario disponer del siguiente software:\n",
    "* Python 2.7 ó 3.X \n",
    "* Jupyter http://jupyter.org/.\n",
    "* Las librerías científicas de Python: NumPy, SciPy, y Matplotlib.\n",
    "* La librería OpenCV\n",
    "* La librería PyMaxFlow\n",
    "\n",
    "El material necesario para la práctica se puede descargar del Aula Virtual en la carpeta ``MaterialesPractica`` del tema de visión estéreo. Esta\n",
    "carpeta contiene:\n",
    "* Una serie de pares estéreo en el directorio images;\n",
    "el sufijo del fichero indica si corresponde a la cámara\n",
    "izquierda (_left) o a la derecha (_right). Bajo el\n",
    "directorio ``rectif`` se encuentran varios pares estéreo\n",
    "rectificados.\n",
    "* Un conjunto de funciones auxiliares de ``Python`` en \n",
    "el módulo ``misc.py``. La descripción de las funciones\n",
    "puede consultarse con el comando help o leyendo\n",
    "su código fuente.\n",
    "* El archivo ``cameras.npz`` con las matrices de proyección del par de cámaras con el que se tomaron todas las imágenes con prefijo minoru."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Condiciones"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* La fecha límite de entrega será el martes 4 de diciembre a las 23:55.\n",
    "* La entrega consiste en dos archivos con el código, resultados y respuestas a los ejercicios:\n",
    "  1. Un \"notebook\" de Jupyter con los resultados. Las respuestas a los ejercicios debes introducirlas en tantas celdas de código o texto como creas necesarias, insertadas inmediatamente después de  un enuciado y antes del siguiente.\n",
    "  2. Un documento \"pdf\" generado a partir del fuente de Jupyter, por ejemplo usando el comando ``jupyter nbconvert --execute --to pdf notebook.ipynb``, o simplemente imprimiendo el \"notebook\" desde el navegador en la opción del menú \"File->Print preview\". Asegúrate de que el documento \"pdf\" contiene todos los resultados correctamente ejecutados.\n",
    "* Esta práctica puede realizarse en parejas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Introducción"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En los problemas de visión estéreo se supondrá la existencia de un par de cámaras calibradas cuyas matrices de proyección $\\mathbf{P}_i$ vienen dadas\n",
    "por $$\\mathbf{P}_1 = \\mathbf{K}_1\\cdot\\begin{bmatrix}\\mathbf{I} & \\mathbf{0}\\end{bmatrix}\\cdot\n",
    "    \\begin{bmatrix}\n",
    "        \\mathbf{R}_1 & \\mathbf{t}_1\\\\ \\mathbf{0}^T & 1\n",
    "    \\end{bmatrix},$$ $$\\mathbf{P}_2 = \\mathbf{K}_2\\cdot\\begin{bmatrix}\\mathbf{I} & \\mathbf{0}\\end{bmatrix}\\cdot\n",
    "    \\begin{bmatrix}\n",
    "        \\mathbf{R}_2 & \\mathbf{t}_2\\\\ \\mathbf{0}^T & 1\n",
    "    \\end{bmatrix}.$$\n",
    "    \n",
    "En esta práctica se usarán las matrices de proyección de\n",
    "dos cámaras para determinar la posición tridimensional\n",
    "de puntos de una escena. Esto es posible siempre que se\n",
    "conozcan las proyecciones de cada punto en ambas cámaras. Desafortunadamente, esta información no suele estar\n",
    "disponible y para obtenerla es preciso emplear el contenido\n",
    "de las imágenes (sus píxeles) en un proceso de búsqueda\n",
    "conocido como puesta en correspondencia. Conocer las matrices de proyección de las cámaras permite acotar el área\n",
    "de búsqueda gracias a las restricciones que proporciona la\n",
    "geometría epipolar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# uncomment to show results in a window\n",
    "%matplotlib tk\n",
    "import numpy as np\n",
    "import scipy.misc as scpm\n",
    "import scipy.ndimage as scnd\n",
    "import matplotlib.pyplot as ppl\n",
    "import numpy.linalg as npla\n",
    "import maxflow.fastmin\n",
    "import misc\n",
    "from pprint import pprint as pp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Reconstrucción"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Teniendo un conjunto de correspondencias entre dos\n",
    "imágenes, con matrices de calibración $P_i$ conocidas, es\n",
    "posible llevar a cabo una reconstrucción tridimensional de\n",
    "dichos puntos. En el fichero ``cameras.npz`` se encuentran\n",
    "las matrices de proyección para las dos cámaras. Para cargar\n",
    "este fichero:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "cameras = np.load(\"cameras.npz\")\n",
    "P1 = cameras[\"left\"]\n",
    "P2 = cameras[\"right\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Todas las imágenes con el prefijo minoru comparten este par de matrices de proyección.\n",
    "\n",
    "Leemos las imágenes y marcammos al menos seis puntos correspondientes en cada una de ella."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "img1 = scpm.imread(\"images/minoru_cube3_left.jpg\")\n",
    "img2 = scpm.imread(\"images/minoru_cube3_right.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "pt1, pt2 = misc.askpoints(img1,img2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ejercicio 1.** Implementa la función ``M = reconstruct(points1, points2, P1, P2)``\n",
    "que, dados una serie de N puntos 2D ``points1`` de la primera imagen y sus \n",
    "N homólogos ``points2`` de la segunda imagen\n",
    "(ambos en coordenadas homogéneas, 3 x N), y el par de matrices\n",
    "de proyección P1 y P2 de la primera y la segunda cámara\n",
    "respectivamente, calcule la reconstrucción tridimensional\n",
    "de cada punto. De ese modo, si ``points1`` y\n",
    "``points2`` son 3 × N , la matriz resultante M debe ser 4 × N.\n",
    "\n",
    "El tipo de reconstrucción debe ser algebraico, no geométrico.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reconstruct(points1, points2, P1, P2):\n",
    "    \"\"\"Reconstruct a set of points projected on two images.\"\"\"\n",
    "    \n",
    "    # Transform homog to cartesian co-ordinates\n",
    "    puntos_cartesianos_1 = points1[:2]\n",
    "    puntos_cartesianos_2 = points2[:2]\n",
    "    # build coefficient matrix and compute reconstruction by least-squares. \n",
    "    # Useful functions are npla.lstsq() and npla.pinv()\n",
    "    min_c = []\n",
    "    m = []\n",
    "    for i in range(len(puntos_cartesianos_1[0])):\n",
    "        a0 = P1[0] - P1[2]*puntos_cartesianos_1[0,i]\n",
    "        a1 = P1[1] - P1[2]*puntos_cartesianos_1[1,i]\n",
    "        ap0 = P2[0] - P2[2]*puntos_cartesianos_2[0,i]\n",
    "        ap1 = P2[1] - P2[2]*puntos_cartesianos_2[1,i]\n",
    "        A = np.array([a0,a1,ap0,ap1])\n",
    "        #pasamos restando la última columna\n",
    "        min_c.append(npla.lstsq(A[:,:3],-A[:,3])[0].tolist())    \n",
    "    return min_c"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reconstruye los puntos marcados y pinta su estructura 3D."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "pixiedust": {
     "displayParams": {}
    },
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<mpl_toolkits.mplot3d.axes3d.Axes3D at 0x7fa692f83fd0>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# reconstruct\n",
    "mM=reconstruct(pt1, pt2, P1, P2)\n",
    "mMT = np.array(mM).T.tolist()\n",
    "# convert from homog to cartesian\n",
    "#pp(mMT)\n",
    "\n",
    "# plot 3D\n",
    "misc.plot3D(mMT[0],mMT[1],mMT[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ejercicio 2.**  Reproyecta los resultados de la reconstrucción\n",
    "en las dos cámaras y dibuja las proyecciones sobre las\n",
    "imágenes originales. Pinta también en otro color los puntos seleccionados manualmente. Comprueba si las proyecciones coinciden con los puntos marcados a mano. Comenta los resultados.\n",
    "Para dibujar los puntos puedes usar la función plothom\n",
    "de la práctica anterior o la versión que se distribuye con esta\n",
    "práctica (misc.plothom)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Proyecto los puntos en ambas cámaras\n",
    "mMT.append([1]*len(mMT[0]))\n",
    "proy1 = np.dot(P1,mMT)\n",
    "proy2 = np.dot(P2,mMT)\n",
    "\n",
    "# Pinto con misc.plothom()\n",
    "ppl.figure()\n",
    "misc.plothom(proy1,'r.')\n",
    "ppl.imshow(img1)\n",
    "ppl.show()\n",
    "\n",
    "ppl.figure()\n",
    "misc.plothom(proy2,'r.')\n",
    "ppl.imshow(img2)\n",
    "ppl.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Geometría epipolar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La geometría epipolar deriva de las relaciones que aparecen en las proyecciones de una escena sobre un par de\n",
    "cámaras. La matriz fundamental $\\mathbf{F}$, que depende exclusivamente de la configuración de las cámaras y no de la escena\n",
    "que éstas observan, es la representación algebráica de dicha\n",
    "geometría: a partir de ella se pueden calcular los epipolos\n",
    "y las líneas epipolares. La relación entre un par de cámaras\n",
    "$\\mathbf{P}_1$, $\\mathbf{P}_2$ y la matriz fundamental es de n -a- 1 (salvo factor de\n",
    "escala). Es decir, dadas dos cámaras calibradas, sólo tienen\n",
    "una matriz fundamental (excepto un factor de escala); dada\n",
    "una matriz fundamental existen infinitas configuraciones de\n",
    "cámaras posibles asociadas a ella."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Estimación de la matriz fundamental"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ejercicio 3.** Implementa la función ``F = projmat2f(P1, P2)``\n",
    "que, dadas dos matrices de proyección, calcule la matriz\n",
    "fundamental asociada a las mismas. $\\mathbf{F}$ debe ser tal que,\n",
    "si $m_1$ de la imagen 1 y $m_2$ de la imagen 2 están en\n",
    "correspondencia, entonces $m_2^\\top F m_1 = 0$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def projmat2f(P1,P2):\n",
    "    \"\"\" Calcula la matriz fundamental a partir de las dos de proyeccion\"\"\"\n",
    "    A,B,b,d = P1[:,:3],P2[:,:3],P1[:,3],P2[:,3]\n",
    "    Ai,Bi = npla.inv(P1[:,:3]),npla.inv(P2[:,:3])\n",
    "    #Calculamos la matrix antisimétrica\n",
    "    M = misc.skew(np.dot(Bi,d)-np.dot(Ai,b))\n",
    "    M = np.dot(Bi.T,np.dot(M,Ai))\n",
    "    return M"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# compute Fundamental matrix\n",
    "F = projmat2f(P1, P2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ejercicio 4** ¿Cómo es la matriz fundamental de dos cámaras\n",
    "que comparten el mismo centro? (Por ejemplo, dos cámaras\n",
    "que se diferencian sólo por una rotación.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nComo sólo depende de la configuración de la cámara, la rotación no afecta a la matriz fundamental \\npor lo que tendrían la misma matriz fundamental.\\n'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Como sólo depende de la configuración de la cámara, la rotación no afecta a la matriz fundamental \n",
    "por lo que tendrían la misma matriz fundamental.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Comprobación de F (OPCIONAL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En los siguientes dos ejercicios vamos a comprobar que la matriz F estimada a partir de P1 y P2 es correcta."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ejercicio 5.** Comprueba que F es la matriz fundamental asociada a las cámaras ``P1`` y ``P2``. Para ello puedes utilizar el resultado 9.12, que aparece en la página 255 del libro Hartley, Zisserman. \"Multipe View Geometry in Computer Vision.\" (sedond edition). Cambridge University Press, 2003."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "También se puede comprobar geométricamente la bondad de una matriz F, si  las epipolares con ella estimadas pasan por el homólogo de un punto dado en una de las imágenes.\n",
    "\n",
    "Dada la matriz fundamental $\\mathbf{F}$ entre las cámaras 1 y 2,\n",
    "se puede determinar, para un determinado punto $m_1$ en la\n",
    "imagen de la cámara 1, cuál es la recta epipolar $l_2$ donde se\n",
    "encontrará su homólogo en la cámara 2: $$l_2 = \\mathbf{F} m_1.$$\n",
    "\n",
    "Las siguientes dos funciones sirven para comprobar esta\n",
    "propiedad. En primer lugar, se necesita una función que\n",
    "dibuje rectas expresadas en coordenadas homogéneas, es\n",
    "decir, la versión de plothom para rectas en lugar de puntos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ejercicio 6.** Implementa la función ``plothline(line)``\n",
    "que, dada una línea expresada en coordenadas homogéneas,\n",
    "la dibuje."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def plothline(line, axes = None):\n",
    "    \"\"\"Plot a line given its homogeneous coordinates.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    line : array_like\n",
    "        Homogeneous coordinates of the line.\n",
    "    axes : AxesSubplot\n",
    "        Axes where the line should be plotted. If not given,\n",
    "        line will be plotted in the active axis.\n",
    "    \"\"\"\n",
    "    if axes == None:\n",
    "        axes = ppl.gca()\n",
    "    \n",
    "    [x0, x1, y0, y1] = axes.axis()\n",
    "\n",
    "    #     (x0, y0) ._____________________. (x1, y0)\n",
    "    #              |                     |\n",
    "    #              |                     |\n",
    "    #              |                     |\n",
    "    #              |                     |\n",
    "    #              |                     |\n",
    "    #              |                     |\n",
    "    #     (x0, y1) .---------------------. (x1, y1)\n",
    " \n",
    "    # TODO: Compute the intersection of the line with the image\n",
    "    # borders.\n",
    "\n",
    "        \n",
    "    # TODO: Plot the line with axes.plot.\n",
    "    #axes.plot(...)\n",
    "    plotline = axes.plot(... , 'r-')\n",
    "    \n",
    "    axes.axis([x0, x1, y0, y1])\n",
    "    return plotline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ejercicio 7.** Completa la función ``plot_epipolar_lines(image1, image2, F)``\n",
    "que, dadas dos imágenes y la matriz fundamental que\n",
    "las relaciona, pide al usuario puntos en la imagen 1 y\n",
    "dibuje sus correspondientes epipolares en la imagen 2 usando ``plothline``."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-12-5445ffa5606d>, line 32)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-12-5445ffa5606d>\"\u001b[0;36m, line \u001b[0;32m32\u001b[0m\n\u001b[0;31m    line =\u001b[0m\n\u001b[0m           ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "def plot_epipolar_lines(image1, image2, F):\n",
    "    \"\"\"Ask for points in one image and draw the epipolar lines for those points.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    image1 : array_like\n",
    "        First image.\n",
    "    image2 : array_like\n",
    "        Second image.\n",
    "    F : array_like\n",
    "        3x3 fundamental matrix from image1 to image2.\n",
    "    \"\"\"\n",
    "    # Prepare the two images.\n",
    "    fig = ppl.gcf()\n",
    "    fig.clf()\n",
    "    ax1 = fig.add_subplot(1, 2, 1)\n",
    "    ax1.imshow(image1)\n",
    "    ax1.axis('image')\n",
    "    ax2 = fig.add_subplot(1, 2, 2)\n",
    "    ax2.imshow(image2)\n",
    "    ax2.axis('image')\n",
    "    ppl.draw()\n",
    "    \n",
    "    ax1.set_xlabel(\"Choose points in left image (or right click to end)\")\n",
    "    point = ppl.ginput(1, timeout=-1, show_clicks=False, mouse_pop=2, mouse_stop=3)\n",
    "    while len(point) != 0:\n",
    "        # point has the coordinates of the selected point in the first image.\n",
    "        point = np.hstack([np.array(point[0]), 1])\n",
    "        ax1.plot(point[0], point[1], '.r')\n",
    "        \n",
    "        # TODO: Determine the epipolar line.\n",
    "        line = \n",
    "        \n",
    "        # Plot the epipolar line with plothline (the parameter 'axes' should be ax2).\n",
    "        plothline(line, axes=ax2)\n",
    "        \n",
    "        ppl.draw()\n",
    "        # Ask for a new point.\n",
    "        point = ppl.ginput(1, timeout=-1, show_clicks=False, mouse_pop=2, mouse_stop=3)\n",
    "    \n",
    "    ax1.set_xlabel('')\n",
    "    ppl.draw()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Utiliza esta función con un par de imágenes llamándola\n",
    "de dos formas diferentes: seleccionando puntos en la imagen\n",
    "izquierda y dibujando las epipolares en la imagen derecha\n",
    "y viceversa. Comprueba en ambos casos que las epipolares\n",
    "siempre pasan por el punto de la segunda imagen correspondiente al seleccionado en la primera. Esto confirmara la corrección de la matriz F.\n",
    "\n",
    "Añade dos figuras una que muestre la selección de puntos en\n",
    "la imagen izquierda y las rectas correspondientes en la\n",
    "imagen derecha, y otra que lo haga al revés. Indica para\n",
    "ambos casos qué matriz fundamental has usado al llamar a\n",
    "``plot_epipolar_lines``."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plot_epipolar_lines( ... TODO ... )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_epipolar_lines(... TODO ...)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  3. Rectificación de imágenes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Es recomendable trabajar a partir de ahora con imágenes\n",
    "en blanco y negro y con valores reales entre 0 y 1 para cada\n",
    "uno de sus píxeles. Eso se puede conseguir con"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "img1 = misc.rgb2gray(img1/255.0)\n",
    "img2 = misc.rgb2gray(img2/255.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La mayoría de algoritmos de puesta en correspondencia,\n",
    "incluyendo el que se va a implementar en esta práctica,\n",
    "requieren que las imágenes de entrada estén rectificadas.\n",
    "\n",
    "Dos imágenes están rectificadas si sus correspondientes epipolares están alineadas horizontalmente. La rectificación de\n",
    "imágenes facilita enormemente los algoritmos de puesta en\n",
    "correspondencia, que pasan de ser problemas de búsqueda\n",
    "bidimensional a problemas de búsqueda unidimensional\n",
    "sobre filas de píxeles de las imágenes. En el material de\n",
    "la práctica se han incluido dos funciones que rectifican\n",
    "(mediante un método lineal) dos imágenes. La función\n",
    "``H1, H2 = misc.projmat2rectify(P1, P2, imsize)``\n",
    "devuelve, dadas las dos matrices de proyección y el tamaño de las imágenes en formato (filas,columnas), las\n",
    "homografías que rectifican, respectivamente, la imagen 1\n",
    "y la imagen 2. La función ``projmat2rectify`` hace uso\n",
    "de ``projmat2f``, por lo que\n",
    "es necesario que esta función esté disponible."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ejercicio 8.** Se tienen dos imágenes no rectificadas ``im1`` e\n",
    "``im2``, y su matriz fundamental asociada $\\mathbf{F}$ . Con el procedimiento explicado, se encuentran un par de homografías $\\mathbf{H}_1$ y $\\mathbf{H}_2$ que dan lugar a las imágenes rectificadas ``O1`` y ``O2``. ¿Cuál es la matriz fundamental $\\mathbf{F}′$ asociada a estas dos imágenes? ¿Por qué?\n",
    "\n",
    "Nota: F ′ depende exclusivamente de F , H1 y H2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "F1 = [[0,0,0],[0,0,-1],[0,1,0]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ejercicio 9.** Rectifica el par de imágenes estéreo ``img1`` e ``img2`` y calcula\n",
    "la matriz fundamental asociada a estas imágenes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "H1, H2 = misc.projmat2rectify(P1,P2,projmat2f,img1.shape)\n",
    "O1, O2 = misc.rectify_images(img1,img2,H1,H2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7fa692cbfb00>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ppl.imshow(O1)\n",
    "ppl.figure()\n",
    "ppl.imshow(O2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ejercicio 10. (opcional)** Calcula y muestra la matriz fundamental de las imágenes\n",
    "rectificadas. Justifica el resultado obtenido (mira la sección 9.3.1 del libro de Hartley y Zisserman, pág. 248 y 249)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Fr=\n",
    "Fr=Fr/Fr[2,1]\n",
    "Fr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ejercicio 11. (Opcional)** Usa ``plot_epipolar_lines`` para dibujar varias líneas epiplares de las imágenes rectificadas. Muestra los resultados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_epipolar_lines(... TODO ...)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Búsqueda de correspondencias"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La búsqueda de correspondencias consigue establecer automáticamente las correspondencias de puntos entre dos\n",
    "imágenes (lo que se ha hecho manualmente en el ejercicio 2)\n",
    "haciendo uso de las restricciones que proporciona la geometría epipolar."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 Cálculo de las medidas de similaridad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Una vez rectificadas las dos imágenes de un par estéreo,\n",
    "se pueden buscar las correspondencias. Una matriz de disparidades $\\mathbf{S}$ indica, para cada píxel de la imagen 1\n",
    "rectificada, a cuántos píxeles de diferencia está su correspondencia\n",
    "en la imagen 2 rectificada. En nuestra práctica, para simplificar el problema, vamos a considerar que los elementos\n",
    "de $\\mathbf{S}$ son enteros. Para el píxel en la posición $(x, y)$ en la\n",
    "imagen 1, su correspondiente está en $(x + S[y, x], y)$ en la\n",
    "imagen 2. Si $S[y, x] < 0$, la correspondencia está hacia la\n",
    "izquierda; si $S[y, x] > 0$, la correspondencia está hacia la\n",
    "derecha; si $S[y, x] = 0$, las coordenadas de los dos puntos\n",
    "coinciden en ambas imágenes.\n",
    "\n",
    "La búsqueda de correspondencias requiere ser capaz de\n",
    "determinar el parecido visual entre píxeles de dos imágenes.\n",
    "Si los píxeles $m_1$ y $m_2$ son visualmente parecidos, tienen\n",
    "más probabilidad de estar en correspondencia que otros\n",
    "que sean visualmente diferentes. Como la\n",
    "apariencia (el nivel de gris) de un único píxel es propensa\n",
    "al ruido y poco discriminativa, el elemento de puesta en\n",
    "correspondencia será una ventana centrada en el píxel.\n",
    "Dado un píxel $m$ de una imagen, llamaremos vecindad\n",
    "del píxel de radio $K$ al conjunto de píxeles de la imagen que se encuentren dentro de una ventana de tamaño\n",
    "$(2K + 1) × (2K + 1)$ píxeles centrada en $m$ . El número de\n",
    "píxeles de una vecindad de radio $K$ es $N = (2K + 1)^2$.\n",
    "Dadas dos vecindades $w_1$ y $w_2$ de dos píxeles, el parecido\n",
    "visual entre ellas puede calcularse con la suma de *diferencias\n",
    "al cuadrado (SSD)* de cada una de sus componentes\n",
    "$$d_{SSD}(\\mathbf{v}, \\mathbf{w}) = \\sum_{i=1}^N(\\mathbf{v}_i - \\mathbf{w}_i)^2.$$\n",
    "\n",
    "La distancia $d_{SSD}$ es siempre positiva, es pequeña cuando\n",
    "dos ventanas son visualmente parecidas y grande en caso\n",
    "contrario."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ejercicio 12.** Implementa la función\n",
    "``C = localssd(im1, im2, K)``\n",
    "que calcula la suma de diferencias al cuadrado entre las\n",
    "ventanas de radio K de la imagen 1 y la imagen 2. El\n",
    "resultado debe ser una matriz del mismo tamaño que las\n",
    "imágenes de entrada que contenga en cada punto el valor\n",
    "de $d_{SSD}$ para la ventana de la imagen 1 y la ventana\n",
    "de la imagen 2 centradas en él. Es decir, $C[i,j]$ debe\n",
    "ser el resultado de $d_{SSD}$ para las ventanas centradas en\n",
    "$im1[i,j]$ e $im2[i,j]$.\n",
    "\n",
    "Para este ejercicio puede resultar útil la función\n",
    "``scipy.ndimage.convolve``."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def localssd(im1, im2, K):\n",
    "    \"\"\"\n",
    "    The local sum of squared differences between windows of two images.\n",
    "    \n",
    "    The size of each window is (2K+1)x(2K+1).\n",
    "    \"\"\"\n",
    "    matriz_disparidad = (im1-im2)**2\n",
    "    mascara = np.ones([2*K+1,2*K+1])\n",
    "    matriz_convolve = scnd.convolve(matriz_disparidad,mascara,mode=\"constant\",cval = 0)\n",
    "    return matriz_convolve"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ejercicio 13.** Implementa la función ``D = ssd_volume(im1, im2, disps, K)`` que calcula la suma de diferencias al cuadrado entre las\n",
    "ventanas de la imagen ``im1`` y la imagen ``im2`` desplazada\n",
    "horizontalmente. El parámetro ``disps`` debe ser una lista\n",
    "de valores indicando las disparidades que se usarán para desplazar la imagen ``im2``. Por ejemplo, si ``disps`` es\n",
    "``np.arange(-3,2)``, se llamará 5 veces a ``localssd`` para la\n",
    "imagen 1 y la imagen 2 desplazada −3 , −2 , −1 , 0 y 1 píxeles\n",
    "en sentido horizontal. K es el parámetro que indica el radio\n",
    "de las ventanas usado por localssd.\n",
    "\n",
    "El valor devuelto D será un array de tamaño $M × N × L$,\n",
    "donde L es el número de disparidades indicadas por ``disps``,\n",
    "``L = len(disps)`` (es decir, el número de veces que se ha\n",
    "llamado a ``localssd``); M y N son, respectivamente, el\n",
    "número de filas y de columnas de las imágenes de entrada.\n",
    "El elemento ``D[y,x,l]`` debe ser la SSD entre la ventana\n",
    "centrada en ``im1[y,x]`` y la ventana centrada en ``im2[y,x + disps[l]]``.\n",
    "\n",
    "``D[y,x,l]`` debe ser muy grande para aquellos valores en\n",
    "los que ``im2[y,x + disps[l]]`` no esté definido, es decir,\n",
    "el índice``(y,x+disps[l])`` se sale de la imagen 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "array([[ inf,  inf,  inf,   1.,   1.,   1.],\n",
      "       [ inf,  inf,  inf,   1.,   1.,   1.],\n",
      "       [ inf,  inf,  inf,   1.,   1.,   1.]])\n"
     ]
    }
   ],
   "source": [
    "array_inf = np.ones((3,3))*np.inf\n",
    "imagen = np.ones((3,3))\n",
    "array_inf = np.hstack((array_inf,imagen))\n",
    "pp(array_inf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ssd_volume(im1, im2, disps, K):\n",
    "    \"\"\"\n",
    "    Calcula el volumen de disparidades SSD\n",
    "    \"\"\"\n",
    "    L = len(disps)\n",
    "    #matriz_nml = np.zeros(im1.shape,L)\n",
    "    matriz_nml = np.zeros(im1.shape + tuple([L]))\n",
    "    for i in range(len(disps)):\n",
    "        #ponemos infinitos para evitar problemas al calcular la disparidad\n",
    "        array_inf = np.ones((im1.shape[0],abs(disps[i])))*np.inf\n",
    "        d = disps[i]\n",
    "        if d > 0:\n",
    "            imx = im2[:,d:]\n",
    "            imx = np.hstack((imx,array_inf))\n",
    "        elif d < 0:\n",
    "            imx = im2[:,:d]\n",
    "            imx = np.hstack((array_inf,imx))\n",
    "        matriz_nml[:,:,i] = localssd(im1,imx,K)\n",
    "    return matriz_nml\n",
    "\n",
    "matriz = ssd_volume(O1,O2,np.arange(-3,2),5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ejercicio 14.** El conjunto de disparidades ``disps`` debe ser lo más pequeño posible, para mejorar el rendimiento de la optimización. Determina un procedimiento para estimar manualmente el conjunto de disparidades posibles y aplícalo a las imágenes O1 y O2."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ppl.figure()\n",
    "ppl.imshow(O1,cmap = \"gray\")\n",
    "ppl.figure()\n",
    "ppl.imshow(O2,cmap = \"gray\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lo hacemos a ojo mirando la esquina más cercana y la más lejana\n",
    "disps = np.arange(125,205)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aplica la función ``ssd_volume`` al par de imágenes O1 y O2\n",
    "con las disparidades estimadas en el ejercicio anterior."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(656, 495, 80)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "D = ssd_volume(O2, O1, disps, 5)\n",
    "\n",
    "# to speed-up the optimization ahead, discard the par of the image showing only background\n",
    "\n",
    "D.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 Estimación de la disparidad sin regularizar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La matriz D calculada en el ejercicio anterior proporciona\n",
    "los costes unitarios $D_i$ de una función de energía sin regularización de la forma $$E(x) = \\sum_{i} D_i(x_i),$$\n",
    "donde $D_i(l)$ viene dado por $D[y,x,l]$, suponiendo que\n",
    "el píxel $i$ tenga coordenadas $(x, y)$. Las variables \n",
    "$x = (x_1 ,\\ldots, x_{NM})$ indican las etiquetas de cada uno de los\n",
    "píxeles. En este caso, las etiquetas son los índices del\n",
    "array ``disps``, que a su vez son las disparidades horizontales.\n",
    "Por eso, a partir de aquí se hablará indistintamente de\n",
    "etiquetas y disparidades. Sólo es necesario recordar que la\n",
    "etiqueta $l$ está asociada a la disparidad ``disps[l]``.\n",
    "\n",
    "\n",
    "Minimizando la energía $x = \\arg\\min_x E(x)$,\n",
    "se obtiene un vector de etiquetas óptimo $x^*$ que indica, para\n",
    "cada píxel, cuál es su disparidad horizontal entre las dos\n",
    "imágenes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ejercicio 15.** Minimiza $E(x)$ y muestra las disparidades resultantes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.colorbar.Colorbar at 0x7fa692fd2438>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res = D.argmin(2)\n",
    "ppl.imshow(res,cmap='gray')\n",
    "ppl.colorbar()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Estimación de la disparidad regularizada"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El etiquetado usando exclusivamente términos unitarios\n",
    "es muy sensible al ruido y propenso a que aparezcan zonas\n",
    "de píxeles cercanos con mucha variación en las etiquetas.\n",
    "Esto es especialmente notable en zonas planas (es decir, sin\n",
    "textura) de las imágenes originales, donde no hay suficiente\n",
    "información para establecer una correspondencia basándose\n",
    "exclusivamente en la apariencia visual de ventanas pequeñas. Por eso es necesario incluir un término de suavizado\n",
    "o regularización en la función de energía. Los tipos de\n",
    "saltos de etiquetas que aparecerán en el resultado final\n",
    "dependerán de cómo sea ese término de suavizado.\n",
    "\n",
    "La función de energía que utilizaremos para calcular\n",
    "las disparidades en la práctica será el resultado de añadir\n",
    "a la expresión (6) un término que penalice los cambios de\n",
    "disparidad en los píxeles vecinos: $$E_r(x) = \\sum_{i} D_i(x_i) + \\lambda\\sum_{ij} \\min(k,|x_i-x_j|).$$ Siendo $j$ los índices de los píxeles vecinos del $i$ en la imagen.\n",
    "La solución al problema de la correspondencia vendrá dado\n",
    "por el conjunto de etiquetas (disparidades) de los píxeles de\n",
    "la imagen que minimicen $E_r(x)$.\n",
    "\n",
    "En [Yuri Boykov, Olga Veksler, and Ramin Zabih. \"Fast approximate\n",
    "energy minimization via graph cuts\". *IEEE Transactions on Pattern\n",
    "Analysis and Machine Intelligence*, 23:1222–1239, 2001.] se presentan métodos para resolver algunos problemas de optimización con varias etiquetas empleando\n",
    "algoritmos de cortes de grafos. Es recomendable repasar las\n",
    "secciones 5 y 8."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ejercicio 16.** Escribe la función ``find_corresp_aexpansion(D, initLabels, lmb, maxV)``,\n",
    "que recie un volumen ssd, ``D``, un conjunto inicial de\n",
    "etiquetas, ``initLabels``, que puede ser el obtenido en el\n",
    "ejercicio 5, el valor de la constante $\\lambda$, y el valor máximo\n",
    "de la función de coste $|x_i − x_j|$, que tendrás que establecer empíricamente. El resultado de esta función serán las\n",
    "etiquetas que minimizan $E_r(x)$. Para ello debes utilizar la función ``maxflow.fastmin.aexpansion_grid(D, V, max_cycles=None, labels=None)`` del paquete\n",
    "*PyMaxFlow*, que resuelve el problema anterior mediante un\n",
    "algoritmo de cortes de grafos empleando una $\\alpha$-expansión."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_corresp_aexpansion(D, initialLabels, lmb, maxV):\n",
    "    \n",
    "    \n",
    "    return "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Llama a esta función y muestra una figura con las etiquetas que resulten de la minimización de la energía para el volumen ssd ``D`` (este proceso puede durar varios minutos)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = find_corresp_aexpansion(D, res, ... , ...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ppl.imshow(labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La matriz de etiquetas óptimas X obtenida de la minimización de la función de energía puede transformarse en\n",
    "la matriz de disparidades S indexando en cada una de sus\n",
    "celdas el array de disparidades disps ``S = disps[X]``.\n",
    "Ahora, el píxel de coordenadas (x, y) de la primera imagen\n",
    "rectificada tendrá su correspondencia en el píxel de coordenadas (x + S [y, x], y) de la segunda imagen rectificada.\n",
    "\n",
    "El siguiente ejercicio usa la matriz de disparidades para\n",
    "establecer automáticamente las correspondencias entre un\n",
    "par de imágenes sin rectificar."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ejercicio 15.** Implementa la función\n",
    "``plot_correspondences(image1, image2, S, H1,H2)``\n",
    "que, dado un par de imágenes sin rectificar, la matriz de\n",
    "disparidades entre las imágenes rectificadas y las homogra-\n",
    "fías que llevan de las imágenes sin rectificar a las imágenes\n",
    "rectificadas, pida al usuario puntos en la primera imagen y\n",
    "dibuje sus correspondencias en la segunda."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_correspondences(image1, image2, S, H1, H2):\n",
    "    \"\"\"\n",
    "    Ask for points in the first image and plot their correspondences in\n",
    "    the second image.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    image1, image2 : array_like\n",
    "        The images (before rectification)\n",
    "    S : array_like\n",
    "        The matrix of disparities.\n",
    "    H1, H2 : array_like\n",
    "        The homographies which rectify both images.\n",
    "    \"\"\"\n",
    "    # Prepare the two images.\n",
    "    fig = ppl.gcf()\n",
    "    fig.clf()\n",
    "    ax1 = fig.add_subplot(1, 2, 1)\n",
    "    ax1.imshow(image1)\n",
    "    ax1.axis('image')\n",
    "    ax2 = fig.add_subplot(1, 2, 2)\n",
    "    ax2.imshow(image2)\n",
    "    ax2.axis('image')\n",
    "    ppl.draw()\n",
    "    \n",
    "    ax1.set_xlabel(\"Choose points in left image (or right click to end)\")\n",
    "    point = ppl.ginput(1, timeout=-1, show_clicks=False, mouse_pop=2, mouse_stop=3)\n",
    "    while len(point) != 0:\n",
    "        # point has the coordinates of the selected point in the first image.\n",
    "        point = np.c_[np.array(point), 1].T\n",
    "        ax1.plot(point[0,:], point[1,:], '.r')\n",
    "        \n",
    "        # TODO: Determine the correspondence of 'point' in the second image.\n",
    "        # perhaps you have to swap the image co-ordinates.\n",
    "        \n",
    "        \n",
    "        # TODO: Plot the correspondence with ax2.plot.\n",
    "        \n",
    "\n",
    "        ax2.plot(... ,... ,'r.')\n",
    "        \n",
    "        ppl.draw()\n",
    "        # Ask for a new point.\n",
    "        point = ppl.ginput(1, timeout=-1, show_clicks=False, mouse_pop=2, mouse_stop=3)\n",
    "    \n",
    "    ax1.set_xlabel('')\n",
    "    ppl.draw()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "S = ... TODO ...\n",
    "plot_correspondences(...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
